{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from functools import wraps\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# torch packages\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.utils import make_grid\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "#from torch.masked import masked_tensor, as_masked_tensor\n",
    "\n",
    "#DMD packages\n",
    "from pydmd import DMD\n",
    "from pydmd.plotter import plot_eigs, plot_summary\n",
    "#from pydmd.preprocessing import hankel_preprocessing\n",
    "\n",
    "\n",
    "FILENAME = 'DLDMD_SIC_v1'\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/\"+FILENAME+\"_\" + time.strftime(\"%Y%m%d-%H%M%S\")+ \".txt\"),\n",
    "        #logging.StreamHandler()  #logs to console as well\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#import custom modules\n",
    "sys.path.append(r'../src/modules/')\n",
    "\n",
    "from plot_jupyter import contour_compare, contour_data\n",
    "from data_wrangle import get_days_before, get_test_set, window_mean\n",
    "#from dmd_routines import reshape_data2dmd, train_dmd, reshape_Psi2data, eval_dmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed for repeatable results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "gen1 = torch.Generator().manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the SIC data set\n",
    "with open(r'C:/Project/data/data314_years_1989_2023.pkl', 'rb') as f:\n",
    "    m, Y, Y_mean_month, Y_mean_week, x2, y2 = dill.load(f)\n",
    "\n",
    "# mask = array of T/F plotting out the land mass of Antartica\n",
    "\n",
    "mask = ~m  \n",
    "DATA = Y\n",
    "x = x2\n",
    "y = y2\n",
    "del Y_mean_month, Y_mean_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data with a plot\n",
    "\n",
    "# fig_1, ax_1 = plt.subplots(figsize=(5,4))\n",
    "\n",
    "# ax_1.contourf(DATA[30][350], cmap=plt.get_cmap('Blues_r'))\n",
    "# ax_1.set_ylim(314, 0)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "#plt.imshow(DATA[30][350], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iiee_loss (c_m, c_o, c_e = 0.15):\n",
    "\n",
    "    model_edge  = c_m >= c_e\n",
    "    observed_edge = c_o >= c_e\n",
    "\n",
    "    a_pos = torch.logical_and(model_edge, ~observed_edge)\n",
    "    a_neg = torch.logical_and(~model_edge, observed_edge)\n",
    "\n",
    "    a_pos_area = torch.sum(a_pos)\n",
    "    a_neg_area = torch.sum(a_neg)\n",
    "\n",
    "\n",
    "    iiee = a_pos_area + a_neg_area\n",
    "    bias = a_pos_area - a_neg_area\n",
    "\n",
    "    return iiee, bias, a_pos_area, a_neg_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = torch.Tensor(DATA[30][350])\n",
    "\n",
    "# observed = torch.Tensor(DATA[30][349])\n",
    "\n",
    "# iiee_loss(predicted, observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step parameter\n",
    "step_thin = 3\n",
    "\n",
    "# ~ is a binary operator flips 1 to 0 and vice versa\n",
    "\n",
    "mask = ~m[::step_thin, ::step_thin]\n",
    "\n",
    "x = x2[::step_thin]\n",
    "y = y2[::step_thin]\n",
    "\n",
    "nx = len(x)\n",
    "ny = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the data set size with the step paramter only for model searching/training\n",
    "DATA = []\n",
    "for year in range(len(Y)):\n",
    "    y0 = Y[year][:, ::step_thin, ::step_thin]\n",
    "    DATA.append(y0)\n",
    "\n",
    "DATA[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check thinned data with a plot\n",
    "# plt.contourf(DATA[30][350], cmap=plt.get_cmap('Blues_r'))\n",
    "# plt.show()\n",
    "\n",
    "# #plt.imshow(DATA[30][350], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year within data set\n",
    "year = 25\n",
    "\n",
    "# day within year as the starting point \n",
    "day = 0\n",
    "\n",
    "# window-averaging\n",
    "window = 1\n",
    "\n",
    "num_year_data = 25\n",
    "\n",
    "# how many days worth of data needed\n",
    "T_train = 365 * num_year_data\n",
    "\n",
    "#batch size for dataloader\n",
    "batchSize = 420\n",
    "\n",
    "X0_ = get_days_before(DATA, year, day, T_train+window-1)\n",
    "\n",
    "\n",
    "#numpy array to torch tensor\n",
    "all_data = torch.Tensor(X0_)[:,None,:,:]\n",
    "\n",
    "mask_tensor = torch.Tensor(np.tile(mask, (X0_.shape[0],1,1,1))).bool()\n",
    "\n",
    "# train_count = 20*365\n",
    "# val_split = 5*365\n",
    "\n",
    "\n",
    "# data_max ,data_min, data_avg = all_data.max(), all_data.min(), all_data.mean()\n",
    "\n",
    "#all_data_train, all_data_val = torch.utils.data.random_split(all_data, [train_count, val_split], generator=gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ = get_test_set(DATA, year, day, window, 365*2)\n",
    "\n",
    "all_test_data = np.array(X1_)\n",
    "all_test_data = torch.Tensor(all_test_data)[:,None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test dataloaders\n",
    "\n",
    "train_loader_sic = torch.utils.data.DataLoader(dataset=all_data, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "#train_loader_sic = torch.utils.data.DataLoader(dataset=all_data_train, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "#val_loader_sic  = torch.utils.data.DataLoader(dataset=all_data_val, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "test_loader_sic = torch.utils.data.DataLoader(dataset=all_test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideWindowDataset(Dataset):\n",
    "    def __init__(self, data, window):\n",
    "        self.data = data\n",
    "        self.window = window\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index:index+self.window]\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_dataset = SlideWindowDataset(all_data[:-365,...], 730)\n",
    "\n",
    "sic_dataset_pred = SlideWindowDataset(all_data[365:,...], 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_sic_window = torch.utils.data.DataLoader(dataset=sic_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "train_loader_sic_window_pred = torch.utils.data.DataLoader(dataset=sic_dataset_pred, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = next(iter(train_loader_sic_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax, ax1) = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "# contourf_ = ax.contourf(A[0][1], cmap=plt.get_cmap('Blues_r'))\n",
    "# cbar = fig.colorbar(contourf_)\n",
    "\n",
    "# contourf_1 = ax1.contourf(A[1][0], cmap=plt.get_cmap('Blues_r'))\n",
    "# cbar1 = fig.colorbar(contourf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmd_training_snapshots( snapshots, n_prediction_snapshots):\n",
    "    if n_prediction_snapshots > 0:\n",
    "        return snapshots[: -n_prediction_snapshots,...]\n",
    "    return snapshots\n",
    "\n",
    "def dmd_prediction_snapshots( snapshots,n_prediction_snapshots):\n",
    "    if n_prediction_snapshots > 0:\n",
    "        return snapshots[-n_prediction_snapshots :,...]\n",
    "    return torch.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = all_data[0]\n",
    "\n",
    "\n",
    "# maxpool = nn.MaxPool2d(4)\n",
    "\n",
    "# img = nn.Conv2d(1, 4, kernel_size=2)(img)\n",
    "# img = nn.Dropout2d(p=0.1)(img)\n",
    "# img = nn.ReLU()(img)\n",
    "# img = nn.Conv2d(4, 8, kernel_size=3 ,stride=2)(img)\n",
    "# img = nn.Dropout2d(p=0.1)(img)\n",
    "# img = nn.ReLU()(img)\n",
    "# img = nn.Conv2d(8, 16, kernel_size=3, stride=3)(img)\n",
    "# img = nn.Dropout2d(p=0.1)(img)\n",
    "# img = nn.ReLU()(img)\n",
    "# img = nn.Conv2d(16, 32, kernel_size=2, stride=2)(img)\n",
    "# img = nn.Dropout2d(p=0.1)(img)\n",
    "# img = nn.ReLU()(img)\n",
    "# img = nn.Conv2d(32, 64, kernel_size=2)(img)\n",
    "# #img = maxpool(img)\n",
    "# img = nn.Flatten()(img[None,:,:])\n",
    "# img = nn.Linear(3136, 64)(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_sharp(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_latent = 64):\n",
    "        \"\"\" \n",
    "        Encoder using `nn.Module`. Series of 2d-Convolutions, dropouts and Relus\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.layers = nn.Sequential(\n",
    "                                        # nn.Conv2d(1, 8, kernel_size=3),\n",
    "                                        # nn.ReLU(),\n",
    "                                        #nn.MaxPool2d(2),\n",
    "                                        nn.Conv2d(1, 16, kernel_size=3),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(3),\n",
    "                                        nn.BatchNorm2d(16),\n",
    "                                        nn.Conv2d(16, 32, kernel_size=3),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(32, 64, kernel_size=3),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.MaxPool2d(2),\n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        # nn.Conv2d(64, 64, kernel_size=3),\n",
    "                                        # nn.ReLU(),\n",
    "                                        # nn.MaxPool2d(2),\n",
    "                                        # nn.BatchNorm2d(64),\n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(160000, self.d_latent)\n",
    "                                    )\n",
    "        \n",
    "        self.layers2 = nn.Sequential(\n",
    "                                    nn.Linear(self.d_latent, 160000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Unflatten(1, (64, 50, 50)),\n",
    "                                    nn.ConvTranspose2d(64, 16, kernel_size=3,stride = 3),\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ConvTranspose2d(16, 8, kernel_size=3, stride = 2),\n",
    "                                    nn.BatchNorm2d(8),\n",
    "                                    nn.ConvTranspose2d(8, 4, kernel_size=3),\n",
    "                                    nn.Conv2d(4, 1, kernel_size=2, padding = 6)\n",
    "                                    #nn.Conv2d(1, 1, kernel_size=1))\n",
    "                                    )    \n",
    "    def forward(self, X):\n",
    "        h1 = self.layers(X)\n",
    "        #h1 = self.layers2(h1)\n",
    "        return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_sharp(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_latent = 64):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.layers = nn.Sequential(\n",
    "                                    nn.Linear(self.d_latent, 160000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Unflatten(1, (64, 50, 50)),\n",
    "                                    nn.ConvTranspose2d(64, 16, kernel_size=3,stride = 3),\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ConvTranspose2d(16, 8, kernel_size=3, stride = 2),\n",
    "                                    nn.BatchNorm2d(8),\n",
    "                                    nn.ConvTranspose2d(8, 4, kernel_size=3),\n",
    "                                    nn.Conv2d(4, 1, kernel_size=2, padding = 6)\n",
    "                                    #nn.Conv2d(1, 1, kernel_size=1))\n",
    "                                    )    \n",
    "        #self.layernom = nn.LayerNorm()\n",
    "    def forward(self, Z):\n",
    "        h1 = self.layers(Z)\n",
    "        return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_latent = 64):\n",
    "        \"\"\" \n",
    "        Encoder using `nn.Module`. Series of 2d-Convolutions, dropouts and Relus\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.layers = nn.Sequential(\n",
    "                                        nn.Conv2d(1, 8, kernel_size=3),\n",
    "                                        #nn.Dropout2d(p=0.1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
    "                                        #nn.Dropout2d(p=0.1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "                                        #nn.Dropout2d(p=0.1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(32, 64, kernel_size=3),\n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(33856, self.d_latent)\n",
    "                                    )\n",
    "    def forward(self, X):\n",
    "        h1 = self.layers(X)\n",
    "        return h1\n",
    "    \n",
    "    #try 5, 3,3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_latent = 64):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_latent = d_latent\n",
    "        self.layers = nn.Sequential(\n",
    "                                    nn.Linear(self.d_latent, 33856),\n",
    "                                    # 400\n",
    "                                    nn.ReLU(),\n",
    "                                    #nn.Linear(28224, 40000),\n",
    "                                    # 4000\n",
    "                                    #nn.ReLU(True),\n",
    "                                    nn.Unflatten(1, (64, 23, 23)),\n",
    "                                    # 10 x 20 x 20\n",
    "                                    nn.ConvTranspose2d(64, 16, kernel_size=3, stride = 3),\n",
    "                                    # 24 x 24\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.ConvTranspose2d(16, 8, kernel_size=3, stride = 2),\n",
    "                                    nn.ConvTranspose2d(8, 4, kernel_size=3),\n",
    "                                    nn.ConvTranspose2d(4, 1, kernel_size=3,padding =19),\n",
    "                                    nn.BatchNorm2d(1)\n",
    "                                    )\n",
    "       \n",
    "        #self.layernom = nn.LayerNorm()\n",
    "    def forward(self, Z):\n",
    "        h1 = self.layers(Z)\n",
    "        return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dmd_enc_dec(nn.Module):\n",
    "    def __init__(self,encoder, decoder, dmd_train, n_prediction_snapshots):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.dmd_train = dmd_train\n",
    "        self.n_prediction_snapshots = n_prediction_snapshots\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output_en = self.encoder(input)\n",
    "        #print(input.shape, output_en.shape)\n",
    "        self.dmd_train.fit(output_en.T, batch=False)\n",
    "        self.dmd_train.dmd_time[\"tend\"] = self.dmd_train.original_time[\"tend\"] + self.n_prediction_snapshots\n",
    "        dmd_recon =  self.dmd_train.reconstructed_data\n",
    "\n",
    "        if not torch.is_complex(input):\n",
    "            old_dtype = dmd_recon.dtype\n",
    "            dmd_recon = dmd_recon.real\n",
    "            logger.debug(\n",
    "                f\"Removing complex part from output_immersion: {old_dtype} to {dmd_recon.dtype}\"\n",
    "            )\n",
    "        if dmd_recon.dtype != input.dtype:\n",
    "            logger.debug(\n",
    "                f\"Casting output_immersion dtype from {dmd_recon.dtype} to {input.dtype}\"\n",
    "            )\n",
    "            dmd_recon = dmd_recon.to(dtype=input.dtype)\n",
    "\n",
    "        output = self.decoder(dmd_recon.T)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIC_DMD = DMD(svd_rank=-1)\n",
    "n_prediction_snapshots = 365\n",
    "\n",
    "enc = Encoder(d_latent=64)\n",
    "dec = Decoder(d_latent=64)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    enc.to(\"cuda\")  \n",
    "    dec.to(\"cuda\")\n",
    "    dmddl = dmd_enc_dec(enc,dec, SIC_DMD,n_prediction_snapshots)\n",
    "    dmddl.to(\"cuda\")  \n",
    "\n",
    "summary(enc, (1,105,105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = Encoder_sharp(d_latent=64)\n",
    "# dec = Decoder_sharp(d_latent=64)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     enc.to(\"cuda\")  \n",
    "#     dec.to(\"cuda\")  \n",
    "\n",
    "# summary(enc, (1,314,314))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper online code to auto update activation shapes\n",
    "\n",
    "# class Network(torch.nn.Module):\n",
    "#     @staticmethod\n",
    "#     def calc_activation_shape(\n",
    "#         dim, ksize, dilation=(1, 1), stride=(1, 1), padding=(0, 0)\n",
    "#     ):\n",
    "#         def shape_each_dim(i):\n",
    "#             odim_i = dim[i] + 2 * padding[i] - dilation[i] * (ksize[i] - 1) - 1\n",
    "#             return (odim_i / stride[i]) + 1\n",
    "\n",
    "\n",
    "#         return shape_each_dim(0), shape_each_dim(1)\n",
    "\n",
    "\n",
    "#     def __init__(self, idim, num_classes=10):\n",
    "#         self.layer1 = torch.nn.Conv2D(3, 5, 3)\n",
    "#         ln_shape = Network.calc_activation_shape(idim, 3) # <--- Calculate the shape of output of Convolution\n",
    "#         self.norm1 = torch.nn.LayerNorm([5, *ln_shape]) # <--- Normalize activations over C, H, and W (see fig.above)\n",
    "#         self.layer2 = torch.nn.Conv2D(5, 10, 3)\n",
    "#         ln_shape = Network.calc_activation_shape(ln_shape, 3)\n",
    "#         self.norm2 = torch.nn.LayerNorm([10, *ln_shape])\n",
    "#         self.layer3 = torch.nn.Dense(num_classes)\n",
    "\n",
    "\n",
    "#     def __call__(self, inputs):\n",
    "#         x = F.relu(self.norm1(self.layer1(input)))\n",
    "#         x = F.relu(self.norm2(self.layer2(x)))\n",
    "#         x = F.sigmoid(self.layer3(x))\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Code ends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Turn into a function with loss type, normalise type, weight decay, learning rate, print paramters, print at all ####\n",
    "\n",
    "#### Need to take avg loss and compare for early stopping criteria ####\n",
    "\n",
    "#### more epochs => significant overfitting ####\n",
    "\n",
    "#### Retrain on full training set after finding optimal epoch range ####\n",
    "to_run = True\n",
    "\n",
    "if to_run: \n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    dmddl.train()\n",
    "\n",
    "    # define loss and parameters\n",
    "\n",
    "    optimizer = optim.Adam(itertools.chain(enc.parameters(), dec.parameters(), dmddl.parameters()), lr=0.0001)\n",
    "    epochs = 120 \n",
    "    \n",
    "    mse_multp = 1.0\n",
    "    #cls_multp = 0.5\n",
    "\n",
    "    print('====Training start====')\n",
    "    for epoch in range(epochs):\n",
    "        total_reconloss = 0.0\n",
    "        total_predloss = 0.0\n",
    "        #train_loss = 0\n",
    "        for batch_idx, data in enumerate(zip(train_loader_sic_window, train_loader_sic_window_pred)):\n",
    "            # prepare input data\n",
    "            #data[0].to(\"cuda\"), data[1].to(\"cuda\") \n",
    "            #img_pred = data[1].to(\"cuda\")\n",
    "            for i in zip(data[0], data[1]):\n",
    "                img = i[0].to(\"cuda\")\n",
    "                img_pred = i[1].to(\"cuda\")\n",
    "                # img.to(\"cuda\")\n",
    "                # img_pred.to(device='cuda')\n",
    "            #img = img*mask_tensor\n",
    "            \n",
    "                output = dmddl(img)\n",
    "\n",
    "                output_clamp = output.clamp(min=0, max= 1) #*mask_tensor\n",
    "\n",
    "                reconstruction_loss = mse_loss(dmd_training_snapshots(output,n_prediction_snapshots), img)\n",
    "\n",
    "                prediction_loss = mse_loss(dmd_prediction_snapshots(output,n_prediction_snapshots), img_pred)\n",
    "                \n",
    "                loss = reconstruction_loss + prediction_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Track this epoch's loss\n",
    "                total_reconloss += reconstruction_loss.item()\n",
    "                total_predloss += prediction_loss.item()\n",
    "\n",
    "            # if epoch==0 or epoch ==10:    \n",
    "            #     print(list(enc.parameters())[0]) \n",
    "            #total_clsloss += loss_cls.item()\n",
    "\n",
    "        # if epoch%10==0:    \n",
    "\n",
    "        #     # add validation step \n",
    "        #     enc.eval()\n",
    "        #     dec.eval()\n",
    "\n",
    "                #total_val_loss = 0 \n",
    "            \n",
    "        #     with torch.no_grad():\n",
    "        #         for batch_idx_val, data_val in enumerate(val_loader_sic):\n",
    "\n",
    "        #             img = data.to(\"cuda\")                       \n",
    "                    \n",
    "        #             output_en = enc(img)\n",
    "        #             output = dec(output_en)\n",
    "\n",
    "        #             output_clamp = output.clamp(min=0, max= 1)#*mask_tensor\n",
    "\n",
    "        #             #output_norm = (output - output.min())/(output.max() - output.min())\n",
    "\n",
    "        #             #masked validation\n",
    "        #             #masked_output = torch.Tensor(masked_tensor(output_clamp, mask_tensor))\n",
    "        #             #masked_img = torch.Tensor(masked_tensor(img, mask_tensor))\n",
    "\n",
    "        #             #mask_tensor.detach()\n",
    "\n",
    "        #             val_loss_mse = distance(img, output_clamp)\n",
    "                    \n",
    "        #             #loss_mse = distance(masked_img, masked_output)\n",
    "        #             #loss_cls = class_loss(output_en, labels)\n",
    "        #             #loss = (mse_multp * loss_mse) + (cls_multp * loss_cls) \n",
    "\n",
    "        #             val_loss = (mse_multp * val_loss_mse) #+ (cls_multp * loss_cls) \n",
    "        #             total_val_loss += val_loss\n",
    "            \n",
    "        #     enc.train()\n",
    "        #     dec.train()\n",
    "\n",
    "            print('====> Epoch: {} Total Recon loss: {:.9f} Total Pred loss: {:.9f}'.format(epoch, total_reconloss,  total_predloss))\n",
    "            #print(list(enc.parameters())[0]) \n",
    "    print('====Training finish====')\n",
    "\n",
    "    torch.save(enc, 'model_outputs/sic_dmdenc_1_no_mask_latent64_' + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    torch.save(dec, 'model_outputs/sic_dmddec_1_no_mask_latent64_' + time.strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect loss and add plot \n",
    "\n",
    "# add validation code and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(enc.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = next(iter(train_loader_sic))[0][None,...]\n",
    "\n",
    "x_train=x_train.cuda()\n",
    "\n",
    "latent = enc(x_train)\n",
    "latent_cpu = enc(x_train).detach().cpu()\n",
    "plt.plot(latent_cpu.T)\n",
    "plt.show()\n",
    "\n",
    "x_train = x_train.detach().cpu().numpy()\n",
    "\n",
    "recon = dec(latent).clamp(min= 0, max=1)#*mask_tensor\n",
    "recon = recon.detach().cpu().numpy()\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "contourf_ = ax.contourf(x_train[0][0], cmap=plt.get_cmap('Blues_r'))\n",
    "cbar = fig.colorbar(contourf_)\n",
    "\n",
    "contourf_1 = ax1.contourf(recon[0][0], cmap=plt.get_cmap('Blues_r'))\n",
    "cbar1 = fig.colorbar(contourf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = next(iter(test_loader_sic))[100][None,...]\n",
    "#x_test2 = next(iter(test_loader_sic))[0][None,...]\n",
    "\n",
    "x_test=x_test.cuda()\n",
    "#x_test2 = x_test2.cuda()\n",
    "\n",
    "latent_test = enc(x_test)\n",
    "latent_test_cpu = enc(x_test).detach().cpu()\n",
    "\n",
    "plt.plot(latent_test_cpu.T)\n",
    "plt.show()\n",
    "\n",
    "x_test = x_test.detach().cpu().numpy()\n",
    "recon_test = dec(latent_test).clamp(min=0, max =1)#*mask_tensor\n",
    "recon_test = recon_test.detach().cpu().numpy()\n",
    "\n",
    "fig1, (ax2, ax3) = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "contourf_2 = ax2.contourf(x_test[0][0], cmap=plt.get_cmap('Blues_r'))\n",
    "cbar = fig1.colorbar(contourf_2)\n",
    "\n",
    "contourf_3 = ax3.contourf(recon_test[0][0], cmap=plt.get_cmap('Blues_r'))\n",
    "cbar1 = fig1.colorbar(contourf_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = next(iter(test_loader_sic))\n",
    "\n",
    "X_test_all = X_test_all.cuda()#*mask_tensor\n",
    "\n",
    "enc_test = enc(X_test_all)\n",
    "dec_test = dec(enc_test).clamp(min=0, max =1 )#*mask_tensor\n",
    "\n",
    "\n",
    "X_test = X_test_all.permute(1,0,2,3)[0]\n",
    "\n",
    "dec_test = dec_test.permute(1,0,2,3)[0]\n",
    "\n",
    "x_true, x_predict = X_test.flatten(), dec_test.flatten()\n",
    "\n",
    "err = (x_true - x_predict)**2 #/ x_test.shape[0]\n",
    "\n",
    "total_err =  err.sum().detach().cpu().numpy()\n",
    "avg_err = total_err/err.shape[0] *100\n",
    "\n",
    "print(total_err,avg_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To load models ###\n",
    "\n",
    "load_ext = True\n",
    "\n",
    "if load_ext:\n",
    "    trained_enc  = Encoder_sharp()\n",
    "    trained_dec = Decoder_sharp()\n",
    "\n",
    "    trained_enc = torch.load(\"model_outputs/sic_enc_sharp1_no_mask_latent64_20240611-201106.pt\")\n",
    "    trained_dec = torch.load(\"model_outputs/sic_dec_sharp1_no_mask_latent64_20240611-201106.pt\")\n",
    "else:\n",
    "    trained_enc  = enc\n",
    "    trained_dec = dec\n",
    "\n",
    "\n",
    "# def load_model(load_ext = False):\n",
    "\n",
    "#     return trained_e, trained_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_DMD_train_orig = get_days_before(DATA, 25, day, 365*2+window-1)\n",
    "\n",
    "X0_DMD_train = torch.Tensor(X0_DMD_train_orig)[:,None,:,:]\n",
    "\n",
    "train_loader_sic_dmd = torch.utils.data.DataLoader(dataset=X0_DMD_train, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get SVD of dataset ###\n",
    "\n",
    "U,S, Vh = torch.linalg.svd(torch.Tensor(X0_DMD_train_orig[0]))\n",
    "\n",
    "# set up temporal range\n",
    "t_delay = [-i for i in range(730)]\n",
    "\n",
    "t_delay_fwd = [i for i in range(730)]\n",
    "\n",
    "t_delay.sort(reverse=False)\n",
    "t_delay_fwd.sort()\n",
    "\n",
    "t_delay_all = t_delay + t_delay_fwd\n",
    "\n",
    "t_delya_arr = np.array(t_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dmd = DMD(svd_rank=5)\n",
    "\n",
    "latent_dmd_delay = hankel_preprocessing(latent_dmd, d=100)\n",
    "\n",
    "latent_bopdmd = BOPDMD(svd_rank=5, eig_constraints={\n",
    "                                \"stable\", # choose Re(lambda)<0\n",
    "                                \"conjugate_pairs\", # force complex conjugate pairs\n",
    "                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dmd = next(iter(train_loader_sic_dmd)) #[:,None,:,:]\n",
    "x_train_dmd = x_train_dmd.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_output = trained_enc(x_train_dmd)\n",
    "\n",
    "latent_output_cpu = latent_output.detach().cpu().numpy().T\n",
    "\n",
    "\n",
    "# Run standard DMD\n",
    "latent_dmd.fit(latent_output_cpu)\n",
    "\n",
    "# DMD modes\n",
    "Psi_ = latent_dmd.modes\n",
    "# Get eigenvalues:\n",
    "Lambda_ = latent_dmd.eigs\n",
    "# The b_n: IC, expressed in modes basis\n",
    "bn_ = latent_dmd.amplitudes\n",
    "\n",
    "\n",
    "# Run BOPDMD #  ---- Need to explain why this is better than DMD use Kutz paper for evidence/rational\n",
    "\n",
    "latent_bopdmd.fit(latent_output_cpu,t= t_delay)\n",
    "\n",
    "Psi_bop = latent_bopdmd.modes\n",
    "# Get eigenvalues:\n",
    "Lambda_bop = latent_bopdmd.eigs\n",
    "# The b_n: IC, expressed in modes basis\n",
    "bn_bop = latent_bopdmd.amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check reconstruction using PYDMD functions  #notbook Autoencoder_SIC\n",
    "\n",
    "dmd_recon = latent_dmd.reconstructed_data\n",
    "\n",
    "bopddm_recon = latent_bopdmd.reconstructed_data\n",
    "\n",
    "plot_summary(latent_dmd)\n",
    "\n",
    "plot_summary(latent_bopdmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the latent space and repsective reconstructions \n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(latent_output_cpu.T)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dmd_recon.T)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(latent_output_cpu.T)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(bopddm_recon.T)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_bopdmd_forecast = latent_bopdmd.forecast(t_delay_fwd)\n",
    "\n",
    "BOPDMDM_forecast_dec = trained_dec(torch.Tensor(latent_bopdmd_forecast.T).cuda())\n",
    "\n",
    "#BOPDMDM_forecast_dec_norm = (BOPDMDM_forecast_dec - BOPDMDM_forecast_dec.min())/(BOPDMDM_forecast_dec.max() - BOPDMDM_forecast_dec.min())\n",
    "\n",
    "BOPDMDM_forecast_dec = BOPDMDM_forecast_dec.permute(1,0,2,3)\n",
    "\n",
    "BOPDMDM_forecast_dec_norm = BOPDMDM_forecast_dec.clamp(min=0, max= 1)\n",
    "\n",
    "BOPDMDM_forecast_dec_norm = BOPDMDM_forecast_dec_norm.detach().cpu().numpy()\n",
    "\n",
    "B1 = BOPDMDM_forecast_dec_norm[0][0]\n",
    "\n",
    "plt.contourf(X0_DMD_train[729][0], cmap=plt.get_cmap('Blues_r'))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "x_truth = next(iter(test_loader_sic))[0][0]\n",
    "\n",
    "plt.contourf(x_truth, cmap=plt.get_cmap('Blues_r'))\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(B1, cmap=plt.get_cmap('Blues_r'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_compare(X1_, BOPDMDM_forecast_dec_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_all = np.arange(-T_train, T_train)\n",
    "#true_after = get_test_set(DATA, year, day, window, T_train)\n",
    "#X_true = np.concatenate((X0, true_after), axis = 0)\n",
    "\n",
    "#X_pred = eval_dmd(Lambda, Psi, bn, t_all)\n",
    "# COMPUTE METRIC OF PREDICTION\n",
    "\n",
    "Integral_pred = np.trapz(np.trapz(BOPDMDM_forecast_dec_norm[0], x, axis = 2), y, axis = 1)\n",
    "Integral_true = np.trapz(np.trapz(X1_, x, axis = 2), y, axis = 1)\n",
    "\n",
    "plt.plot(t_delay_fwd, Integral_pred, color = 'grey');\n",
    "plt.plot(t_delay_fwd, Integral_true, label = 'true total ice', color = 'r')\n",
    "\n",
    "plt.axvline(0, linestyle = '--', color = 'k')\n",
    "\n",
    "plt.ylabel('total ice')\n",
    "plt.xlabel('days')\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "# plt.xlim([-120, 10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icedmd1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
